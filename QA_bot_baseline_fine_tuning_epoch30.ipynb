{"cells":[{"cell_type":"markdown","metadata":{"id":"Z9Ciu62NpJax"},"source":["# QA bot baseline\n","## Pretrained Model Load(SKT-KoGPT2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4230,"status":"ok","timestamp":1731911886218,"user":{"displayName":"임승수","userId":"07868405882142888382"},"user_tz":-540},"id":"f1qwKQ9vrwLf","outputId":"806db90b-b2cc-4a8e-c507-e90239d2f2ee"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}],"source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","                                                    bos_token='</s>',\n","                                                    eos_token='</s>',\n","                                                    unk_token='<unk>',\n","                                                    pad_token='<pad>',\n","                                                    mask_token='<mask>')\n","#tokenizer.tokenize(\"</s> 안녕하세요. 한국어 GPT-2 입니다.😤:)l^o </s>\")"]},{"cell_type":"code","source":["tokenizer.tokenize(\"</s> 봄 에 입을 옷 종류를 추천해주세요. </s>\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6J0POqwFKjuA","executionInfo":{"status":"ok","timestamp":1731911886218,"user_tz":-540,"elapsed":8,"user":{"displayName":"임승수","userId":"07868405882142888382"}},"outputId":"51210bbd-1f03-4d63-f741-4a6a8a93dc0d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['</s>', '▁봄', '▁에', '▁입을', '▁옷', '▁종류를', '▁추천', '해주', '세', '요.', '▁', '</s>']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["tokenizer.tokenize(\"</s> 봄에 입을 옷 종류를 추천해주세요. </s>\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2NUY1gJKkeb","executionInfo":{"status":"ok","timestamp":1731911886218,"user_tz":-540,"elapsed":6,"user":{"displayName":"임승수","userId":"07868405882142888382"}},"outputId":"c7911943-08a7-4452-f2f9-b67278aaad71"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['</s>', '▁봄에', '▁입을', '▁옷', '▁종류를', '▁추천', '해주', '세', '요.', '▁', '</s>']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5195,"status":"ok","timestamp":1731911891409,"user":{"displayName":"임승수","userId":"07868405882142888382"},"user_tz":-540},"id":"DMohjsyl0O3-","outputId":"b1ce4291-5d74-4531-9ca3-025f557c6e02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2SdpaAttention(\n","          (c_attn): Conv1D(nf=2304, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=768)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D(nf=3072, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=3072)\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"metadata":{},"execution_count":4}],"source":["import torch\n","from transformers import GPT2LMHeadModel\n","\n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"auoElfwb4RfH"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2347,"status":"ok","timestamp":1731911893753,"user":{"displayName":"임승수","userId":"07868405882142888382"},"user_tz":-540},"id":"Ai4WW5rjdkUO","outputId":"3ca02708-a4aa-4995-fd7f-af1524a66e48"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# 구글 드라이브 마운트\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojpLLfh50Ozc"},"outputs":[],"source":["import json\n","\n","def load_data(filepath):\n","    with open(filepath, 'r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    pairs = []\n","    for entry in data[\"data_info\"]:\n","        question = entry[\"question\"]\n","        answer = entry[\"answer\"][\"contents\"]\n","        pairs.append((question, answer))\n","\n","    return pairs"]},{"cell_type":"code","source":["filepath_test = '/content/drive/MyDrive/Project2/Data/SFTlabel.json'\n","pairs_test = load_data(filepath_test)\n","print(pairs_test[3])"],"metadata":{"id":"T8PUc3kMuVwt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731911893753,"user_tz":-540,"elapsed":13,"user":{"displayName":"임승수","userId":"07868405882142888382"}},"outputId":"ff0734df-531d-4bf5-85d1-aec9d7becff0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('도자기를 고르게 돌리기 위해 사용하는 도구의 이름은?', \"도자기를 고르게 돌리기 위해 사용하는 도구는 '도마'입니다. 도마는 도자기를 고르게 회전시켜주는 원형의 도구로서 주로 도자기 공방이나 도자기 작업 공간에서 사용됩니다.\")\n"]}]},{"cell_type":"code","source":["filepath_validation = '/content/drive/MyDrive/Project2/Data/SFTlabel_Validation.json'\n","pairs_validation = load_data(filepath_validation)\n","print(pairs_validation[3])"],"metadata":{"id":"OkloMSsCua7g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731911893753,"user_tz":-540,"elapsed":7,"user":{"displayName":"임승수","userId":"07868405882142888382"}},"outputId":"41a57712-af93-4a04-8ee7-a4fb40ab0150"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('유리공예 작업할 때 필요한 도구와 재료가 뭐야?', '유리공예 작업을 위해 필요한 도구 및 재료는 다음과 같습니다:\\n\\n도구\\n1. 유리 절단 칼: 유리를 원하는 크기로 절단하기 위해 사용됩니다.\\n2. 선과: 직선을 그리기 위해 사용됩니다.\\n3. 절단 접착제: 접합을 위해 사용되며, 강력한 접착제로 유리 조각이 붙는 데 도움을 줍니다.\\n4. 모래 지속기: 유리의 끝을 다듬기 위해 사용됩니다.\\n5. 소화기: 작업 도중 작은 불꽃이 발생할 경우 안전을 위해 사용됩니다.\\n6. 연마 도구: 유리의 표면을 연마하여 다듬을 수 있습니다.\\n7. 벤치 그라인더: 유리를 모양을 다듬는 데 사용되며, 모양을 좀 더 정확하게 조정할 수 있습니다.\\n8. 페인트 브러시: 디자인과 색상을 유리에 그릴 때 사용됩니다.\\n\\n재료\\n1. 유리 조각: 다양한 크기, 모양, 색상의 유리 조각을 사용할 수 있습니다.\\n2. 테두리: 유리 작품을 보호하거나 견고하게 만들기 위해 사용됩니다.\\n3. 줄무늬: 작품을 걸거나 장식할 때 사용되며, 다양한 색상과 재질을 사용할 수 있습니다.\\n4. 트림: 테두리를 꾸미거나 작품의 외관을 강조하기 위해 사용됩니다.\\n5. 유리그릇: 작품에 사용될 수 있는 꽃, 모래, 컬러드 샌드 등의 재료를 담을 수 있습니다.\\n6. 폴리싱 제품: 유리의 표면을 광택 내기 위해 사용됩니다.\\n7. 에나멜 그릇: 유리에 그림을 그리고 색칠하기 위해 사용됩니다.\\n8. 용제: 유리 조각을 부착하거나 다른 재료를 붙이기 위해 사용됩니다.\\n\\n다양한 도구와 재료를 사용하여 유리공예 작업을 즐기고 다양한 작품을 만들 수 있습니다!')\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8d53ahWVG08F"},"outputs":[],"source":["# for param in model.transformer.parameters():\n","#     param.requires_grad = False\n","\n","# for param in model.lm_head.parameters():\n","#     param.requires_grad = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WsdH5ZCV0Osd"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","\n","class QADataset(Dataset):\n","    def __init__(self, qa_pairs, tokenizer, max_length=256):\n","        self.qa_pairs = qa_pairs\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.qa_pairs)\n","\n","    def __getitem__(self, idx):\n","        question, answer = self.qa_pairs[idx]\n","        input_text = f\"</s> 질문: {question} 답변: {answer} </s>\"\n","\n","        encoding = self.tokenizer(\n","            input_text,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        input_ids = encoding['input_ids'].squeeze()\n","        attention_mask = encoding['attention_mask'].squeeze()\n","\n","        # labels를 input_ids의 복사본으로 생성\n","        labels = input_ids.clone()\n","\n","        # 패딩 토큰에 대한 손실을 무시하기 위해 패딩 토큰 인덱스를 -100으로 설정\n","        labels[input_ids == self.tokenizer.pad_token_id] = -100\n","\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': labels\n","        }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfnEYSCqp2Fe"},"outputs":[],"source":["from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4mKerzfIp0ie"},"outputs":[],"source":["train_dataset = QADataset(pairs_test, tokenizer)\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","val_dataset = QADataset(pairs_validation, tokenizer)\n","val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1731911894162,"user":{"displayName":"임승수","userId":"07868405882142888382"},"user_tz":-540},"id":"WFEOzt5h33G8","outputId":"50c549dc-abf9-41ef-e224-c441ca7d56c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["662\n","10580\n","torch.Size([16, 256])\n","torch.Size([16, 256])\n","torch.Size([16, 256])\n","83\n","1322\n","torch.Size([16, 256])\n","torch.Size([16, 256])\n","torch.Size([16, 256])\n"]}],"source":["# DataLoader에서 배치 샘플 확인\n","\n","print(len(train_dataloader))\n","print(len(train_dataloader.dataset))\n","\n","for batch in train_dataloader:\n","    print(batch['input_ids'].shape)  # (batch_size, max_length)\n","    print(batch['attention_mask'].shape)  # (batch_size, max_length)\n","    print(batch['labels'].shape)  # (batch_size, max_length)\n","    break\n","\n","print(len(val_dataloader))\n","print(len(val_dataloader.dataset))\n","\n","for batch in val_dataloader:\n","    print(batch['input_ids'].shape)  # (batch_size, max_length)\n","    print(batch['attention_mask'].shape)  # (batch_size, max_length)\n","    print(batch['labels'].shape)  # (batch_size, max_length)\n","    break"]},{"cell_type":"markdown","metadata":{"id":"j5RsVxtY4aXu"},"source":["## Model Fine-tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vduhiwmp7fiE"},"outputs":[],"source":["def save_model(model, tokenizer, epoch):\n","  save_directory = '/content/drive/MyDrive/Project2/fine_tuned2_kogpt2_epoch' + str(epoch+1)\n","\n","  model.save_pretrained(save_directory)\n","  tokenizer.save_pretrained(save_directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":758},"id":"snMOEgHA33D8","outputId":"153ddf54-7e79-4316-b3fe-b3f9f816242a","executionInfo":{"status":"error","timestamp":1731915376706,"user_tz":-540,"elapsed":3479941,"user":{"displayName":"임승수","userId":"07868405882142888382"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss: 2.5498781204223633, Validation Loss: 2.6303213619324097\n","Epoch: 1, Loss: 2.5196614265441895, Validation Loss: 2.554392087890441\n","Epoch: 2, Loss: 2.2004594802856445, Validation Loss: 2.5338284710803665\n","Epoch: 3, Loss: 2.026648759841919, Validation Loss: 2.5389505380607513\n","Epoch: 4, Loss: 1.7974423170089722, Validation Loss: 2.549360525177186\n","Epoch: 5, Loss: 2.128162384033203, Validation Loss: 2.56954034839768\n","Epoch: 6, Loss: 1.9983564615249634, Validation Loss: 2.598156104604882\n","Epoch: 7, Loss: 1.7069597244262695, Validation Loss: 2.6202958664262153\n","Epoch: 8, Loss: 1.5984896421432495, Validation Loss: 2.6580891896443193\n","Epoch: 9, Loss: 1.41572105884552, Validation Loss: 2.6896425902125345\n","Epoch: 10, Loss: 1.3024977445602417, Validation Loss: 2.726694095565612\n","Epoch: 11, Loss: 1.3147656917572021, Validation Loss: 2.758708973965013\n","Epoch: 12, Loss: 1.1436717510223389, Validation Loss: 2.7997053387653397\n","Epoch: 13, Loss: 0.9771098494529724, Validation Loss: 2.822834138410637\n","Epoch: 14, Loss: 1.0590531826019287, Validation Loss: 2.8623261394270934\n","Epoch: 15, Loss: 1.0168726444244385, Validation Loss: 2.8910653275179574\n","Epoch: 16, Loss: 0.8337737321853638, Validation Loss: 2.924210706389094\n","Epoch: 17, Loss: 0.7476286292076111, Validation Loss: 2.9521899338228157\n","Epoch: 18, Loss: 0.8373007774353027, Validation Loss: 2.978858284203403\n","Epoch: 19, Loss: 0.7808645367622375, Validation Loss: 3.0028041299567163\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-c086108a48ad>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","from torch.utils.data import DataLoader\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","num_epochs = 30\n","\n","\n","# Dataset과 DataLoader 정의\n","# train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n","\n","# 옵티마이저와 스케줄러 정의\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","total_steps = len(train_dataloader) * num_epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=total_steps)\n","\n","# 학습 루프\n","for epoch in range(num_epochs):\n","    model.train()\n","    for batch in train_dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids=input_ids, labels=labels)\n","        loss = outputs.loss\n","\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","    model.eval()  # 검증 모드\n","    val_loss = 0\n","    with torch.no_grad():  # 그래디언트 계산 비활성화\n","        for batch in val_dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, labels=labels)\n","            val_loss += outputs.loss.item()\n","\n","    val_loss /= len(val_dataloader)  # 평균 검증 손실 계산\n","    print(f\"Epoch: {epoch}, Loss: {loss.item()}, Validation Loss: {val_loss}\")\n","\n","    if (epoch + 1) % 5 == 0:\n","        save_model(model, tokenizer, epoch)"]},{"cell_type":"markdown","metadata":{"id":"YhYdBqGS5Jf6"},"source":["## Finish"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vrRZhD8X4h50"},"outputs":[],"source":["# 코랩 세션을 종료시켜주세요\n","from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[{"file_id":"1pnrPWELesFwKZSZH7lb4joxRMdvFSIuz","timestamp":1731477979257}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}